{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d210518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression,Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "import bertopic\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:85% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa032153",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.__version__)\n",
    "import scipy\n",
    "print(scipy.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725eff35",
   "metadata": {},
   "source": [
    "# data from Ashwin + plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f063a21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "concern_cols = ['lockdowns','masking','vaccines','therapeutics','education']\n",
    "mf_cols = ['care', 'harm', 'fairness', 'cheating', 'loyalty', 'betrayal', 'authority','subversion'] # , 'purity', 'degradation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03ac62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../covid_data/ts_from_ashwin/'\n",
    "files = glob(data_dir + '*.csv')\n",
    "\n",
    "dfs = {}\n",
    "filenames = []\n",
    "for file in files:\n",
    "    filename = \" \".join(file.split('/')[-1].split('.')[0].split('_')[:2])\n",
    "    filenames.append(filename)\n",
    "    print(filename)\n",
    "    tmp = pd.read_csv(file)\n",
    "    tmp['date'] = pd.to_datetime(tmp['date'])\n",
    "    tmp = tmp[tmp.date >= pd.Timestamp('2020-02-01')]\n",
    "    tmp = tmp.set_index('date')\n",
    "    dfs[filename] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affe345f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_div = {}\n",
    "for c in concern_cols:\n",
    "    dfs_div[c] = dfs['lib '+c] - dfs['cons '+c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e813c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_div['lockdowns']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982dc333",
   "metadata": {},
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b39108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_separate_ts(df,columns,events=[]):\n",
    "    colors = ['coral','navy','turquoise','forestgreen','gold','darkviolet','sienna','grey']\n",
    "    for c,color in zip(columns,colors):\n",
    "        plt.figure()\n",
    "        df[c].plot(figsize=[8,3],kind='line',color=color)\n",
    "        plt.axhline(y=0,color='black')\n",
    "        for e in events:\n",
    "            plt.axvline(pd.Timestamp(e[0]),label=e[1],color='black',linestyle=e[2])\n",
    "        plt.ylabel('Conservative <=> Liberal')\n",
    "        plt.title(c)\n",
    "        plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "          fancybox=True, shadow=True, ncol=3)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699134ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ts(df,columns,events=[],title=''):\n",
    "    plt.figure()\n",
    "    colors = ['coral','navy','turquoise','forestgreen','gold','darkviolet','sienna','grey']# plt.cm.Set2.colors[3:6]+ ('red','dodgerblue','green','darksalmon','grey') # ['coral','navy','turquoise','forestgreen','gold','darkviolet','sienna']\n",
    "    for c,color in zip(columns,colors): \n",
    "        df[c].plot(figsize=[20,6],kind='line',label=c) # ,color=color\n",
    "    for e in events:\n",
    "        plt.axvline(pd.Timestamp(e[0]),color='black',linestyle=e[2]) #,label=e[1])\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Fraction of tweets')\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "      fancybox=True, shadow=True, ncol=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7277876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_compare_ts(df_control,df_target,columns,events=[]):\n",
    "    for c in columns:\n",
    "        plt.figure(figsize=[20,6])\n",
    "        df_control[c].plot(kind='line',color='blue',label='Liberals')\n",
    "        df_target[c].plot(kind='line',color='red',label='Conservatives')\n",
    "        for e in events:\n",
    "            plt.axvline(pd.Timestamp(e[0]),label=e[1],color='black',linestyle=e[2])\n",
    "        plt.title(c)\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12844732",
   "metadata": {},
   "source": [
    "# change points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb09613d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kats\n",
    "from kats.utils.decomposition import TimeSeriesDecomposition\n",
    "from kats.consts import TimeSeriesData\n",
    "from kats.detectors.cusum_detection import CUSUMDetector\n",
    "from kats.detectors.bocpd import BOCPDetector, BOCPDModelType, TrendChangeParameters\n",
    "\n",
    "# use pyenv environment disentangle_emotions\n",
    "# scipy version = 1.7.3\n",
    "# pandas version = 1.3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04affcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def changepoint_detection(df,time_colname,var_colnames,title=''):\n",
    "    changepoints = {}\n",
    "    for c in var_colnames:\n",
    "        # construct ts\n",
    "        tmp_ts = df.reset_index()\n",
    "        tmp_ts = tmp_ts[[time_colname,c]]\n",
    "        tmp_ts[time_colname] = tmp_ts[time_colname].astype(str)\n",
    "        tmp_ts.columns = ['time','value']\n",
    "        ts = TimeSeriesData(tmp_ts)\n",
    "        \n",
    "        cp_list = []\n",
    "\n",
    "        detector = BOCPDetector(ts)\n",
    "        # BOCPD - assume normal distri\n",
    "        cp_list.extend(detector.detector(\n",
    "            model=BOCPDModelType.NORMAL_KNOWN_MODEL,\n",
    "            changepoint_prior = 0.03,\n",
    "            threshold=0.6\n",
    "        ))\n",
    "#         # BOCPD - assume ordinary linear reg. \n",
    "#         cp_list.extend(detector.detector(\n",
    "#             model=BOCPDModelType.TREND_CHANGE_MODEL,\n",
    "#             model_parameters=TrendChangeParameters(\n",
    "#                 readjust_sigma_prior=True, num_points_prior=14\n",
    "#                 ),\n",
    "#                 debug=True,\n",
    "#                 threshold=0.6,\n",
    "#                 choose_priors=False,\n",
    "#                 agg_cp=True\n",
    "#         ))\n",
    "    \n",
    "        # CUSUM - multiple change points\n",
    "        historical_window = 14\n",
    "        scan_window = 7\n",
    "        step = 5\n",
    "        cpts = []\n",
    "        n = len(ts)\n",
    "        for end_idx in range(historical_window + scan_window, n, step):\n",
    "            tsd = ts[end_idx - (historical_window + scan_window) : end_idx]\n",
    "            cpts += CUSUMDetector(tsd).detector(interest_window=[historical_window, historical_window + scan_window])\n",
    "        \n",
    "        # Plot the data, add results\n",
    "        plt.figure(figsize=[20,3])\n",
    "        plt.title(title+\" - \"+c)\n",
    "        detector.plot(cp_list)\n",
    "        plt.figure(figsize=[20,3])\n",
    "        detector1 = CUSUMDetector(ts) # we are not really using this detector\n",
    "        detector1.detector()\n",
    "        detector1.plot(cpts)\n",
    "        cp_list.extend(cpts)\n",
    "\n",
    "        cleaned_list = []\n",
    "        for j in cp_list:\n",
    "            try:\n",
    "                time = pd.Timestamp(j[0].start_time,tz='utc')\n",
    "            except:\n",
    "                time = pd.Timestamp(j[0].start_time)\n",
    "            cleaned_list.append((time,j[0].confidence))\n",
    "            print(time, j[0].confidence)\n",
    "        \n",
    "        idx_to_remove = []\n",
    "        for j in range(1,len(cleaned_list)):\n",
    "            if abs((cleaned_list[j][0] - cleaned_list[j-1][0]).days) <= 5:\n",
    "                idx_to_remove.append(j)\n",
    "        print(idx_to_remove)\n",
    "        cleaned_list = [item for idx,item in enumerate(cleaned_list) if idx not in idx_to_remove]\n",
    "        print(cleaned_list)\n",
    "            \n",
    "        changepoints[c] = cleaned_list\n",
    "    return changepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa27b754",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# BOCPD-normal + CUSUM\n",
    "changepoints = {}\n",
    "\n",
    "# concerns\n",
    "for concern in concern_cols:\n",
    "    print(concern)\n",
    "    \n",
    "    changepoints[concern] = changepoint_detection(dfs_div[concern].reset_index(),'date',mf_cols,title=concern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59af85e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "changepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342da525",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../covid_data/changepoints_covid.pkl','wb') as f:\n",
    "    pickle.dump(changepoints,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377cc3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../covid_data/changepoints_covid.pkl','rb') as f:\n",
    "    changepoints = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1929d67",
   "metadata": {},
   "source": [
    "## measuring changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36201b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_event(time,events):\n",
    "    for e in events:\n",
    "        if time >= pd.Timestamp(e[0])-pd.Timedelta(1,unit='D') and time <= pd.Timestamp(e[0])+pd.Timedelta(1,unit='D'):\n",
    "            event_date = e[0]\n",
    "            return True,e\n",
    "    return False,None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90ab1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_mean_change(df_ts,time_colname,var_colname,event_time,before_window=7,after_window=7):\n",
    "    try:\n",
    "        event_time = pd.Timestamp(event_time, tz='utc')\n",
    "    except:\n",
    "        event_time = pd.Timestamp(event_time)\n",
    "    start_time = event_time - pd.Timedelta(before_window,unit='D')\n",
    "    end_time = event_time + pd.Timedelta(after_window,unit='D')\n",
    "\n",
    "    before_mean = df_ts.loc[(df_ts[time_colname]>=start_time) & (df_ts[time_colname]<event_time),var_colname].mean()\n",
    "    after_mean = df_ts.loc[(df_ts[time_colname]>=event_time) & (df_ts[time_colname]<end_time),var_colname].mean()\n",
    "    \n",
    "    return (after_mean-before_mean)/before_mean*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c810388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "def measure_slope_change(df_ts,time_colname,var_colname,event_time,before_window=7,after_window=7,mode='kink',plot=True):\n",
    "    if mode == 'jump':\n",
    "        effect_coef = 'threshold'\n",
    "    elif mode == 'kink':\n",
    "        effect_coef = 'date_to_int:threshold'\n",
    "    \n",
    "    try:\n",
    "        event_time = pd.Timestamp(event_time, tz='UTC')\n",
    "    except:\n",
    "        event_time = pd.Timestamp(event_time)\n",
    "    start_time = event_time - pd.Timedelta(before_window,unit='D')\n",
    "    end_time = event_time + pd.Timedelta(after_window,unit='D')\n",
    "    \n",
    "    df = df_ts[(df_ts[time_colname]>=start_time) & (df_ts[time_colname]<=end_time)]\n",
    "    df = df.sort_index()\n",
    "    df['date_to_int'] = list(range(len(df)))\n",
    "    event_idx = df.loc[df[time_colname]==event_time,'date_to_int'].item()\n",
    "    df['date_to_int'] = df['date_to_int'] - event_idx # make date_to_int of the event zero\n",
    "    df = df.assign(threshold=(df['date_to_int'] > 0).astype(int))\n",
    "    \n",
    "    model = smf.wls(\"Q('\"+var_colname+\"')~date_to_int*threshold\", df).fit()\n",
    "    ate_pct = round(100*((model.params[effect_coef] + model.params[\"Intercept\"])/model.params[\"Intercept\"] - 1),2)\n",
    "\n",
    "    # plot each regression - data and prediction\n",
    "#     if plot:\n",
    "#         plt.figure()\n",
    "#         df_ = df.copy()\n",
    "#         df_['predictions'] = model.predict()\n",
    "#         df_.plot(x=time_colname, y=\"predictions\", color=\"red\")\n",
    "#         df_.plot(kind='scatter',x=time_colname, y=var_colname)\n",
    "#         plt.title(var_colname+f\" ATE={ate_pct}%\")\n",
    "\n",
    "#     res.loc['effect',c] = model.params[effect_coef]\n",
    "#     res.loc['p-val',c] = model.pvalues[effect_coef]\n",
    "#     res.loc['std_err',c] = model.bse[effect_coef]\n",
    "#     res.loc['change(%)',c] = ate_pct\n",
    "    \n",
    "    return ate_pct, model.pvalues[effect_coef]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14aa963",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_changes = pd.DataFrame()\n",
    "for concern,v in changepoints.items():\n",
    "    tmp_div = dfs_div[concern].reset_index()\n",
    "    for var,changes in v.items():\n",
    "        for c in changes:\n",
    "            # is_valid_cp,event = detect_event(c[0].start_time, events)\n",
    "            # if is_valid_cp: # np.datetime64\n",
    "            mean_change = measure_mean_change(tmp_div,'date', var, c[0])\n",
    "            slope_change,pval = measure_slope_change(tmp_div,'date', var, c[0])\n",
    "            relevant_change = {\n",
    "                'concern':concern,\n",
    "                'variable': var,\n",
    "                'event': None, # event[1],\n",
    "                'event_date': c[0],\n",
    "                'change_point_confidence':c[1],\n",
    "                '%change_in_mean':mean_change,\n",
    "                '%change_in_slope':slope_change,\n",
    "                'slope_change_pval':pval\n",
    "            }\n",
    "            relevant_changes = relevant_changes.append(relevant_change,ignore_index=True)\n",
    "            \n",
    "with open('../covid_data/changes_measured_covid.pkl','wb') as f:\n",
    "    pickle.dump(relevant_changes,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7238a199",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../covid_data/changes_measured_covid.pkl','rb') as f:\n",
    "    relevant_changes = pickle.load(f)\n",
    "relevant_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc58e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_changes[(relevant_changes.concern=='all')& (relevant_changes.variable=='fairness')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e380cd51",
   "metadata": {},
   "source": [
    "# topic modeling\n",
    "\n",
    "scipy version. = 1.10.1\n",
    "pandas version = 1.5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab15342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../covid_data/covid_5perc_sample_200121_200531_processed_w_topics.csv',lineterminator='\\n')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f411b3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.merge(users,how='inner',left_on='screen_name',right_on='username')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d72db79",
   "metadata": {},
   "source": [
    "## bertopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0570e724",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "model = bertopic.backend._utils.select_backend(sentence_model)\n",
    "topic_model = BERTopic.load('../topic_model_all_fairness_2021-05-29', embedding_model=model)\n",
    "\n",
    "len(topic_model.probabilities_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3f84c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_label(idx):\n",
    "    return topic_model.topic_labels_[idx]\n",
    "\n",
    "df['topic_idx'] = topic_model.topics_\n",
    "df['topic'] = df['topic_idx'].apply(get_topic_label)\n",
    "\n",
    "# df.to_csv('../covid_data/covid_5perc_sample_200121_200531_processed_w_topics.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac977445",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# topic_model_all_fairness_2020-06-18\n",
    "topic_model.get_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae50b6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_model_all_fairness_2020-08-26\n",
    "topic_model.get_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a835c05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_model_all_fairness_2021-01-31\n",
    "topic_model.get_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fe2810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_model_all_fairness_2021-04-19\n",
    "topic_model.get_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befeb3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_model_all_fairness_2021-05-29\n",
    "topic_model.get_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc92341",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../covid_5perc_200121_200531_topics_over_time.pkl','rb') as f:\n",
    "    topics_over_time = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77c85c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d562e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topic_model.visualize_topics_over_time(topics_over_time, top_n_topics=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713627d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['date'] = df['date'].dt.round('D')\n",
    "df_topic_freq = df.groupby(['topic_idx','date'])['tweetid'].count()\n",
    "df_topic_freq = df_topic_freq.reset_index()\n",
    "df_topic_freq.columns = ['topic_idx','date','Frequency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4da66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "topics_to_plot = [24]# list(range(10))\n",
    "\n",
    "colors = plt.cm.tab10.colors\n",
    "ax = plt.subplot()\n",
    "for t,c in zip(topics_to_plot,colors):\n",
    "    tmp = df_topic_freq[df_topic_freq.topic_idx==t].sort_values('date')\n",
    "    name = topic_model.topic_labels_[t]\n",
    "    name = \"_\".join(name.split('_')[1:4])\n",
    "    print(name)\n",
    "    tmp.plot('date','Frequency',kind='line',label=name,ax=ax,color=c,figsize=[8,3])\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Frequency')\n",
    "#plt.yscale('log')\n",
    "# plt.ylim((-10,170))\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "          fancybox=True, shadow=True, ncol=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4490c930",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc6c81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0\n",
    "\n",
    "import gensim.corpora as corpora\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['rt','covid','coronavirus','people','pandemic'])\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        # deacc=True removes punctuations\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) \n",
    "             if word not in stop_words] for doc in texts]\n",
    "\n",
    "def gen_LDA_comparison(df,event_date,title=''):\n",
    "    before = df[(df.date>=(event_date-pd.Timedelta(5,unit='D'))) & (df.date<event_date)]\n",
    "    before_text = ' '.join(before['text'].tolist())\n",
    "    before_words = before_text.split()\n",
    "    before_words = remove_stopwords(before_words)\n",
    "    before_id2word = corpora.Dictionary(before_words)\n",
    "    before_corpus = [before_id2word.doc2bow(text) for text in before_words if len(text)>0]\n",
    "    num_topics = 20\n",
    "    before_lda = gensim.models.LdaMulticore(corpus=before_corpus,\n",
    "                                           id2word=before_id2word,\n",
    "                                           num_topics=num_topics,\n",
    "                                           passes=2,\n",
    "                                           iterations=100)\n",
    "    before_topics = before_lda.print_topics(num_words=5)\n",
    "\n",
    "    after = df[(df.date>=event_date) & (df.date<(event_date+pd.Timedelta(5,unit='D')))]\n",
    "    after_text = ' '.join(after['text'].tolist())\n",
    "    after_words = after_text.split()\n",
    "    after_words = remove_stopwords(after_words)\n",
    "    after_id2word = corpora.Dictionary(after_words)\n",
    "    after_corpus = [after_id2word.doc2bow(text) for text in after_words if len(text)>0]\n",
    "    after_lda = gensim.models.LdaMulticore(corpus=after_corpus,\n",
    "                                           id2word=after_id2word,\n",
    "                                           num_topics=num_topics,\n",
    "                                           passes=2,\n",
    "                                           iterations=100)\n",
    "    after_topics = after_lda.print_topics(num_words=5)\n",
    "    \n",
    "    print(title)\n",
    "    print('BEFORE:')\n",
    "    for i in before_topics:\n",
    "        print(i)\n",
    "    print('AFTER:')\n",
    "    for i in after_topics:\n",
    "        print(i)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c5409e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for r,row in relevant_changes.iterrows():\n",
    "    event_date = row['event_date']\n",
    "    if event_date > df['date'].max():\n",
    "        continue\n",
    "    \n",
    "    title = row['concern']+' - '+row['variable']+', '+str(row['event_date'].date())+' '+str(round(row['%change_in_mean'],2))+'%'\n",
    "    \n",
    "    gen_LDA_comparison(df,event_date,title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f338bc",
   "metadata": {},
   "source": [
    "## wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01de6ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../covid_data/covid_5perc_sample_200121_210630_processed.csv',lineterminator='\\n')\n",
    "print(df.columns)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.merge(users,how='inner',left_on='screen_name',right_on='username')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd76c6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['rt','covid','coronavirus','people','pandemic','el','p'])\n",
    " \n",
    "def count_freq(s):\n",
    "    # break the string into list of words\n",
    "    str_list = s.split()\n",
    "\n",
    "    frequency = Counter(str_list)\n",
    "    \n",
    "    # remove stop words\n",
    "    for k in list(frequency.keys()):\n",
    "        if k in stop_words:\n",
    "            del frequency[k]\n",
    "\n",
    "    return frequency\n",
    "\n",
    "def count_freq_diff(d1,d2):\n",
    "    diff = {}\n",
    "    for k,v in d2.items():\n",
    "        if k in d1.keys():\n",
    "            if v > d1[k]:\n",
    "                diff[k] = v - d1[k]\n",
    "        else:\n",
    "            diff[k] = v\n",
    "    return diff\n",
    "\n",
    "def gen_wordcloud_comparison(df,event_date,title=''):\n",
    "    before = df[(df.date>=(event_date-pd.Timedelta(5,unit='D'))) & (df.date<event_date)]\n",
    "    before_text = ' '.join(before['text'].tolist())\n",
    "    before_freq = count_freq(before_text)\n",
    "    \n",
    "    after = df[(df.date>=event_date) & (df.date<(event_date+pd.Timedelta(5,unit='D')))]\n",
    "    after_text = ' '.join(after['text'].tolist())\n",
    "    after_freq = count_freq(after_text)\n",
    "    \n",
    "    diff_freq = count_freq_diff(before_freq,after_freq)\n",
    "    diff_wordcloud = WordCloud().generate_from_frequencies(diff_freq)\n",
    "    \n",
    "    plt.imshow(diff_wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "def gen_wordcloud_LRcomparison(df,event_date,title=''):\n",
    "    before = df[(df.date>=(event_date-pd.Timedelta(5,unit='D'))) & (df.date<event_date)]\n",
    "    beforeL = before[before.political=='left']\n",
    "    beforeL_text = ' '.join(beforeL['text'].tolist())\n",
    "    beforeL_freq = count_freq(beforeL_text)\n",
    "    \n",
    "    beforeR = before[before.political=='right']\n",
    "    beforeR_text = ' '.join(beforeR['text'].tolist())\n",
    "    beforeR_freq = count_freq(beforeR_text)\n",
    "    # before_wordcloud = WordCloud().generate_from_frequencies(before_freq)\n",
    "    \n",
    "    after = df[(df.date>=event_date) & (df.date<(event_date+pd.Timedelta(5,unit='D')))]\n",
    "    afterL = after[after.political=='left']\n",
    "    afterL_text = ' '.join(afterL['text'].tolist())\n",
    "    afterL_freq = count_freq(afterL_text)\n",
    "    \n",
    "    afterR = after[after.political=='right']\n",
    "    afterR_text = ' '.join(afterR['text'].tolist())\n",
    "    afterR_freq = count_freq(afterR_text)\n",
    "    #after_wordcloud = WordCloud().generate_from_frequencies(after_freq)\n",
    "    \n",
    "#     fig,(ax1,ax2)=plt.subplots(nrows=1,ncols=2)\n",
    "#     ax1.imshow(before_wordcloud, interpolation='bilinear')\n",
    "#     ax2.imshow(after_wordcloud, interpolation='bilinear')\n",
    "#     ax1.axis(\"off\")\n",
    "#     ax2.axis(\"off\")\n",
    "    print(len(beforeL_freq),len(beforeR_freq),len(afterL_freq),len(afterR_freq))\n",
    "    \n",
    "    diff_freq_RL = count_freq_diff(count_freq_diff(beforeR_freq,beforeL_freq),count_freq_diff(afterR_freq,afterL_freq))\n",
    "    diff_wordcloud_RL = WordCloud().generate_from_frequencies(diff_freq_RL)\n",
    "    \n",
    "    plt.imshow(diff_wordcloud_RL, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title+', Left says more')\n",
    "    plt.show()\n",
    "    \n",
    "    diff_freq_LR = count_freq_diff(count_freq_diff(beforeL_freq,beforeR_freq),count_freq_diff(afterL_freq,afterR_freq))\n",
    "    diff_wordcloud_LR = WordCloud().generate_from_frequencies(diff_freq_LR)\n",
    "    \n",
    "    plt.imshow(diff_wordcloud_LR, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title+', Right says more')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d2229f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the most different words comparing before and after an event\n",
    "for r,row in relevant_changes.iterrows():\n",
    "    event_date = row['event_date']\n",
    "    if event_date > df['date'].max():\n",
    "        continue\n",
    "    \n",
    "    title = row['concern']+' - '+row['variable']+', '+str(row['event_date'].date())+', divergence (L-R) change='+str(round(row['%change_in_mean'],2))+'%'\n",
    "    \n",
    "    gen_wordcloud_comparison(df,event_date,title)\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a074ad8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the most different words (beforeL-beforeC)-(afterL-afterC)\n",
    "for r,row in relevant_changes.iterrows():\n",
    "    event_date = row['event_date']\n",
    "    if event_date > df['date'].max():\n",
    "        continue\n",
    "    \n",
    "    title = row['concern']+' - '+row['variable']+', '+str(row['event_date'].date())#+\n",
    "    print('divergence (L-R) change='+str(round(row['%change_in_mean'],2))+'%')\n",
    "    gen_wordcloud_LRcomparison(df,event_date,title)\n",
    "    #gen_wordcloud_LRcomparison(df[row.concern]==1,event_date,title)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf97637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the most different words (beforeL-beforeC)-(afterL-afterC)\n",
    "for r,row in relevant_changes.iterrows():\n",
    "    event_date = row['event_date']\n",
    "    if event_date > df['date'].max():\n",
    "        continue\n",
    "    df_tmp = df[df[row.variable]==1]\n",
    "    \n",
    "    title = row['concern']+' - '+row['variable']+', '+str(row['event_date'].date())#+\n",
    "    print('divergence (L-R) change='+str(round(row['%change_in_mean'],2))+'%')\n",
    "    gen_wordcloud_LRcomparison(df_tmp,event_date,title)\n",
    "    #gen_wordcloud_LRcomparison(df[row.concern]==1,event_date,title)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969d095e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
